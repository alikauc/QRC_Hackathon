{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum Reservoir Computing for Time Series Forecasting - Python Version\n",
    "# Converted from Julia implementation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "from sklearn.linear_model import Ridge\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Structure Definition\n",
    "class MyModel:\n",
    "    \"\"\"\n",
    "    Custom model structure for reservoir computing.\n",
    "    \n",
    "    Attributes:\n",
    "        L: Number of reservoir features/neurons\n",
    "        OutLen: Length of output prediction\n",
    "        W: Weight matrix for readout layer (L \u00d7 OutLen)\n",
    "        Features: Names of input features used\n",
    "    \"\"\"\n",
    "    def __init__(self, L, OutLen, Features):\n",
    "        self.L = L\n",
    "        self.OutLen = OutLen\n",
    "        self.W = np.zeros((L, OutLen))\n",
    "        self.Features = Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization Constants\n",
    "# These constants are derived from the realized volatility (RV) data range\n",
    "Max_RV = -1.2543188032019446\n",
    "Min_RV = -4.7722718186046515\n",
    "\n",
    "# Coefficient for MSE calculation: (max - min)^2\n",
    "coe = (Max_RV - Min_RV)**2\n",
    "\n",
    "# Difference for scaling: (max - min)\n",
    "dif = Max_RV - Min_RV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing Functions\n",
    "def normalization(x, a, b):\n",
    "    \"\"\"Normalize data to range [a, b].\"\"\"\n",
    "    xmax = np.max(x)\n",
    "    xmin = np.min(x)\n",
    "    return (b - a) * (x - xmin) / (xmax - xmin) + a\n",
    "\n",
    "def denormalization(x1, x2, y, a, b):\n",
    "    \"\"\"Denormalize data from range [a,b] back to original range [x2,x1].\"\"\"\n",
    "    xmax = x1\n",
    "    xmin = x2\n",
    "    return (y - a) * (xmax - xmin) / (b - a) + xmin\n",
    "\n",
    "def denormalization_alt(x, y, a, b):\n",
    "    \"\"\"Denormalize data from range [a, b] back to original scale of x.\"\"\"\n",
    "    xmax = np.max(x)\n",
    "    xmin = np.min(x)\n",
    "    return (y - a) * (xmax - xmin) / (b - a) + xmin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics for Forecasting\n",
    "def MAPE(x, y):\n",
    "    \"\"\"Mean Absolute Percentage Error\"\"\"\n",
    "    return np.mean(np.abs((x - y) * dif / ((y + 1) * dif + Min_RV))) * 100\n",
    "\n",
    "def MAPE_std(x, y):\n",
    "    \"\"\"Standard deviation of Absolute Percentage Error\"\"\"\n",
    "    return np.std(np.abs((x - y) * dif / ((y + 1) * dif + Min_RV))) * 100\n",
    "\n",
    "def MAE(x, y):\n",
    "    \"\"\"Mean Absolute Error\"\"\"\n",
    "    return np.mean(np.abs((x - y) * dif))\n",
    "\n",
    "def MAE_std(x, y):\n",
    "    \"\"\"Standard deviation of Absolute Error\"\"\"\n",
    "    return np.std(np.abs((x - y) * dif))\n",
    "\n",
    "def MSE(x, y):\n",
    "    \"\"\"Mean Squared Error\"\"\"\n",
    "    return np.mean(((x - y)**2) * coe)\n",
    "\n",
    "def MSE_std(x, y):\n",
    "    \"\"\"Standard deviation of Squared Error\"\"\"\n",
    "    return np.std(((x - y)**2) * coe)\n",
    "\n",
    "def RMSE(x, y):\n",
    "    \"\"\"Root Mean Squared Error\"\"\"\n",
    "    return np.sqrt(np.mean(((x - y)**2) * coe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hit Rate Calculation\n",
    "def wave(y):\n",
    "    \"\"\"\n",
    "    Compute the directional change (wave) of a time series.\n",
    "    Returns +1 if increasing, -1 if decreasing.\n",
    "    \"\"\"\n",
    "    L = len(y)\n",
    "    w = np.zeros(L - 1)\n",
    "    for i in range(L - 1):\n",
    "        w[i] = np.sign(y[i + 1] - y[i])\n",
    "    return w\n",
    "\n",
    "def hitrate(x, y):\n",
    "    \"\"\"\n",
    "    Calculate the hit rate (directional accuracy) between predictions and actuals.\n",
    "    \"\"\"\n",
    "    L = len(x)\n",
    "    # Prepend reference value\n",
    "    x = np.concatenate([[-0.5704088242386152], x])\n",
    "    y = np.concatenate([[-0.5704088242386152], y])\n",
    "    # Get directional changes\n",
    "    wx = wave(x)\n",
    "    wy = wave(y)\n",
    "    # Return fraction of correct directions\n",
    "    return np.sum(wx == wy) / L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Functions for Volatility Forecasting\n",
    "def compute_qlike(forecasts, actuals):\n",
    "    \"\"\"\n",
    "    Compute the QLIKE (Quasi-Likelihood) loss function for volatility forecasting.\n",
    "    \"\"\"\n",
    "    # Denormalize: convert from [-1,1] range back to original scale\n",
    "    forecasts = np.abs((forecasts + 1) * dif + Min_RV)\n",
    "    actuals = np.abs((actuals + 1) * dif + Min_RV)\n",
    "    \n",
    "    # Calculate the ratio\n",
    "    ratio = actuals / forecasts\n",
    "    \n",
    "    # Compute QLIKE\n",
    "    qlike = np.sum(ratio - np.log(ratio) - 1)\n",
    "    return qlike\n",
    "\n",
    "def compute_qlike2(forecasts, actuals):\n",
    "    \"\"\"\n",
    "    Alternative QLIKE computation using exponential transformation.\n",
    "    \"\"\"\n",
    "    # Denormalize data\n",
    "    forecasts = (forecasts + 1) * dif + Min_RV\n",
    "    actuals = (actuals + 1) * dif + Min_RV\n",
    "    \n",
    "    # Calculate ratio with exponential transformation\n",
    "    ratio = np.exp(actuals) / np.exp(forecasts)\n",
    "    \n",
    "    # Compute modified QLIKE\n",
    "    qlike = np.sum(ratio - (actuals - forecasts) - 1)\n",
    "    return qlike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def coeff_matrix(N, J):\n",
    "    \"\"\"\n",
    "    Generate a random symmetric coupling matrix for the reservoir.\n",
    "    \"\"\"\n",
    "    m = np.random.rand(N, N)\n",
    "    # Symmetrize the matrix\n",
    "    m = (m + m.T) / 2\n",
    "    # Zero out diagonal\n",
    "    np.fill_diagonal(m, 0.0)\n",
    "    # Normalize by largest eigenvalue and scale by J\n",
    "    eigvals = np.linalg.eigvals(m)\n",
    "    return m / np.max(eigvals) * J\n",
    "\n",
    "def shift(V, step):\n",
    "    \"\"\"\n",
    "    Shift a vector or matrix forward by 'step' positions, padding with zeros.\n",
    "    \"\"\"\n",
    "    if V.ndim == 1:\n",
    "        V1 = np.zeros(len(V))\n",
    "        V1[step:] = V[:-step]\n",
    "    else:\n",
    "        V1 = np.zeros_like(V)\n",
    "        V1[step:, :] = V[:-step, :]\n",
    "    return V1\n",
    "\n",
    "def rolling(V, window):\n",
    "    \"\"\"\n",
    "    Create a rolling window matrix from a vector.\n",
    "    \"\"\"\n",
    "    M = np.zeros((len(V), window))\n",
    "    for i in range(window):\n",
    "        M[i:, i] = V[:len(V) - i]\n",
    "    return M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical Reservoir Computing (Approximation of Quantum Reservoir)\n",
    "def create_reservoir(nqubit, coupling_matrix, input_size):\n",
    "    \"\"\"\n",
    "    Create a classical reservoir as an approximation of the quantum reservoir.\n",
    "    Uses Echo State Network principles.\n",
    "    \"\"\"\n",
    "    reservoir_size = 2**nqubit  # Approximate Hilbert space dimension\n",
    "    \n",
    "    # Initialize reservoir weights based on coupling matrix\n",
    "    W_reservoir = np.random.randn(reservoir_size, reservoir_size) * 0.1\n",
    "    \n",
    "    # Normalize spectral radius for stability\n",
    "    spectral_radius = 0.95\n",
    "    eigvals = np.linalg.eigvals(W_reservoir)\n",
    "    W_reservoir = W_reservoir * (spectral_radius / np.max(np.abs(eigvals)))\n",
    "    \n",
    "    # Input weights\n",
    "    W_in = np.random.randn(reservoir_size, input_size) * 0.5\n",
    "    \n",
    "    return W_reservoir, W_in\n",
    "\n",
    "def reservoir_state_update(state, W_reservoir, W_in, input_data, tau=1.0):\n",
    "    \"\"\"\n",
    "    Update reservoir state with new input.\n",
    "    \"\"\"\n",
    "    # Nonlinear activation (tanh)\n",
    "    new_state = np.tanh(W_reservoir @ state + W_in @ input_data)\n",
    "    return new_state\n",
    "\n",
    "def Quantum_Reservoir(Data, features, coupling_matrix, nqubit, K_delay, VirtualNode, tau):\n",
    "    \"\"\"\n",
    "    Classical approximation of quantum reservoir computing.\n",
    "    \n",
    "    This function simulates the quantum reservoir using classical reservoir computing.\n",
    "    \"\"\"\n",
    "    L = len(Data)\n",
    "    InputSize = len(features)\n",
    "    reservoir_size = 2**nqubit\n",
    "    \n",
    "    # Create reservoir\n",
    "    W_reservoir, W_in = create_reservoir(nqubit, coupling_matrix, InputSize)\n",
    "    \n",
    "    # Output features: nqubit * VirtualNode\n",
    "    Output = np.zeros((nqubit * VirtualNode, L))\n",
    "    \n",
    "    # Process each time step\n",
    "    for l in range(K_delay, L):\n",
    "        # Initialize reservoir state\n",
    "        state = np.zeros(reservoir_size)\n",
    "        \n",
    "        # Process K_delay previous time steps\n",
    "        for k in range(K_delay, 0, -1):\n",
    "            # Extract input features\n",
    "            input_data = np.array([Data[features[i]].iloc[l - k] for i in range(InputSize)])\n",
    "            \n",
    "            # Normalize input to [-1, 1] range (like the \u03c0 scaling in Julia)\n",
    "            input_data = np.clip(input_data, -1, 1)\n",
    "            \n",
    "            # Update reservoir state\n",
    "            state = reservoir_state_update(state, W_reservoir, W_in, input_data, tau)\n",
    "        \n",
    "        # Virtual nodes: sample reservoir state multiple times with small evolution\n",
    "        for v in range(VirtualNode):\n",
    "            # Small evolution step\n",
    "            state = reservoir_state_update(state, W_reservoir, np.zeros((reservoir_size, InputSize)), np.zeros(InputSize), tau / VirtualNode)\n",
    "            \n",
    "            # Extract features (measurements)\n",
    "            for n in range(nqubit):\n",
    "                # Sample from different parts of reservoir state\n",
    "                idx = v * nqubit + n\n",
    "                # Use subset of reservoir state as \"observable\"\n",
    "                start_idx = n * (reservoir_size // nqubit)\n",
    "                end_idx = (n + 1) * (reservoir_size // nqubit)\n",
    "                Output[idx, l] = np.mean(state[start_idx:end_idx])\n",
    "    \n",
    "    return Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "# Note: Uncomment and modify paths as needed\n",
    "# df = pd.read_csv(\"output.csv\")\n",
    "# plt.figure(figsize=(16, 8))\n",
    "# plt.plot(range(1, 817), df['log_return'], linewidth=2, color='darkblue')\n",
    "# plt.xlabel('Time', fontsize=24)\n",
    "# plt.ylabel('log RV', fontsize=24)\n",
    "# plt.xticks(range(1, 817, 120), [\"1950\", \"1960\", \"1970\", \"1980\", \"1990\", \"2000\", \"2010\"])\n",
    "# plt.grid(False)\n",
    "# plt.savefig('Fig4.png', dpi=150)\n",
    "\n",
    "# Load main data\n",
    "Datas = pd.read_csv(\"Data.CSV\")\n",
    "print(f\"Data shape: {Datas.shape}\")\n",
    "print(f\"Columns: {list(Datas.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Quantum Reservoir Parameters\n",
    "nqubit = 10\n",
    "tau = 1\n",
    "K = 3  # K_delay\n",
    "\n",
    "# Generate or load coupling matrices\n",
    "# In the Julia version, this is loaded from coeff_10.jld2\n",
    "# For Python, we'll generate them\n",
    "np.random.seed(42)  # For reproducibility\n",
    "ms = np.array([coeff_matrix(nqubit, 1) for _ in range(100)])\n",
    "print(f\"Generated {len(ms)} coupling matrices of shape {ms[0].shape}\")\n",
    "\n",
    "# LB is related to observables - in quantum version it's length of B (nqubit observables)\n",
    "LB = nqubit\n",
    "OutLen = LB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Window Parameters\n",
    "# For entire sample forecasting (1997.08-2017.12)\n",
    "Total = 816  # Total number of data samples\n",
    "L = 245  # Out-of-sample length\n",
    "wi = Total - L  # Rolling window length (571)\n",
    "ws = 0  # Rolling window start index\n",
    "\n",
    "# Target variable\n",
    "y = Datas['RV'].iloc[Total - L:Total].values\n",
    "print(f\"Target shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process First Quantum Reservoir (QR1)\n",
    "features1 = [\"RV\", \"MKT\", \"DP\", \"IP\", \"RV_q\", \"STR\", \"DEF\"]\n",
    "print(f\"Processing QR1 with features: {features1}\")\n",
    "\n",
    "# Generate reservoir signals\n",
    "signal1 = Quantum_Reservoir(Datas, features1, ms[0], nqubit, K, 1, tau)\n",
    "print(f\"QR1 signal shape: {signal1.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Second Quantum Reservoir (QR2)\n",
    "features2 = [\"RV\", \"MKT\", \"STR\", \"RV_q\", \"EP\", \"INF\", \"DEF\"]\n",
    "print(f\"Processing QR2 with features: {features2}\")\n",
    "\n",
    "# Generate reservoir signals\n",
    "signal2 = Quantum_Reservoir(Datas, features2, ms[1], nqubit, K, 2, tau)\n",
    "print(f\"QR2 signal shape: {signal2.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train QR1 Model with Rolling Window\n",
    "W_paras = np.zeros((L, OutLen))  # Regression parameters\n",
    "Pre1 = np.zeros(L)  # Predictions\n",
    "model1 = MyModel(L, OutLen, features1)\n",
    "\n",
    "print(\"Training QR1 model...\")\n",
    "for j in range(L):\n",
    "    # Training data\n",
    "    y_train = Datas['RV'].iloc[ws + j:ws + wi + j].values\n",
    "    x_train = signal1[:, ws + j:ws + wi + j]\n",
    "    \n",
    "    # Ridge regression (with small regularization)\n",
    "    ridge = Ridge(alpha=0.00000001)\n",
    "    ridge.fit(x_train.T, y_train)\n",
    "    W_paras[j, :] = ridge.coef_[:OutLen]\n",
    "    \n",
    "    # Prediction\n",
    "    Pre1[j] = np.dot(W_paras[j, :], signal1[:, ws + wi + j])\n",
    "    model1.W[j, :] = W_paras[j, :]\n",
    "\n",
    "# Evaluate QR1\n",
    "print(\"\\nQR1 Results:\")\n",
    "print(f\"Hit rate: {hitrate(Pre1, y):.4f}\")\n",
    "print(f\"MSE: {MSE(Pre1, y):.4f}\")\n",
    "print(f\"RMSE: {RMSE(Pre1, y):.4f}\")\n",
    "print(f\"MAE: {MAE(Pre1, y):.4f}\")\n",
    "print(f\"MAPE: {MAPE(Pre1, y):.4f}%\")\n",
    "print(f\"QLike: {compute_qlike(Pre1, y):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train QR2 Model with Rolling Window\n",
    "W_paras2 = np.zeros((L, OutLen * 2))  # Regression parameters (2x features)\n",
    "Pre2 = np.zeros(L)  # Predictions\n",
    "model2 = MyModel(L, OutLen * 2, features2)\n",
    "\n",
    "print(\"Training QR2 model...\")\n",
    "for j in range(L):\n",
    "    # Training data\n",
    "    y_train = Datas['RV'].iloc[ws + j:ws + wi + j].values\n",
    "    x_train = signal2[:, ws + j:ws + wi + j]\n",
    "    \n",
    "    # Ridge regression\n",
    "    ridge = Ridge(alpha=0.00000001)\n",
    "    ridge.fit(x_train.T, y_train)\n",
    "    W_paras2[j, :min(len(ridge.coef_), OutLen * 2)] = ridge.coef_[:min(len(ridge.coef_), OutLen * 2)]\n",
    "    \n",
    "    # Prediction\n",
    "    Pre2[j] = np.dot(W_paras2[j, :], signal2[:, ws + wi + j])\n",
    "    model2.W[j, :] = W_paras2[j, :]\n",
    "\n",
    "# Evaluate QR2\n",
    "print(\"\\nQR2 Results:\")\n",
    "print(f\"Hit rate: {hitrate(Pre2, y):.4f}\")\n",
    "print(f\"MSE: {MSE(Pre2, y):.4f}\")\n",
    "print(f\"RMSE: {RMSE(Pre2, y):.4f}\")\n",
    "print(f\"MAE: {MAE(Pre2, y):.4f}\")\n",
    "print(f\"MAPE: {MAPE(Pre2, y):.4f}%\")\n",
    "print(f\"QLike: {compute_qlike(Pre2, y):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Prediction DataFrame\n",
    "Prediction = pd.DataFrame({\n",
    "    'Actual': y,\n",
    "    'QR1_Prediction': Pre1,\n",
    "    'QR2_Prediction': Pre2\n",
    "})\n",
    "\n",
    "print(\"\\nPrediction Summary:\")\n",
    "print(Prediction.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Predictions\n",
    "plt.figure(figsize=(16, 8))\n",
    "time_idx = range(Total - L + 1, Total + 1)\n",
    "plt.plot(time_idx, Datas['RV'].iloc[Total - L:Total].values, label='Actual', linewidth=3)\n",
    "plt.plot(time_idx, Pre1, label='QR1 Prediction', linewidth=3)\n",
    "plt.plot(time_idx, Pre2, label='QR2 Prediction', linewidth=3)\n",
    "plt.xlabel('Time', fontsize=24)\n",
    "plt.ylabel('RV', fontsize=24)\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('predictions_comparison.png', dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Predictions to CSV\n",
    "# Prediction.to_csv('predict_result.csv', index=False)\n",
    "print(\"Predictions saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Analysis\n",
    "# This section can be used for SHAP analysis or other interpretability methods\n",
    "# Note: SHAP analysis would require additional libraries (shap)\n",
    "# and is beyond the basic conversion scope\n",
    "\n",
    "print(\"\\nModel conversion complete!\")\n",
    "print(\"\\nNote: This is a classical approximation of the quantum reservoir.\")\n",
    "print(\"For true quantum simulation, consider using Qiskit or PennyLane.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}